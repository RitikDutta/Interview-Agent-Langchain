{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAI.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-drNHtucRPzoqyWkvGNwUT3BlbkFJRubm9F0usp18DmY37rEM\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAI.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "openai.api_key = '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'\n",
    "API = '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'\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(question):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=question,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "cred = credentials.Certificate(\"/home/codered/mystuff/progs/interview-mentor-firebase-adminsdk-sguq7-aee5c6cca8.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_message_to_firestore(user, message, response):\n",
    "    doc_ref = db.collection('interviews').document()\n",
    "    doc_ref.set({\n",
    "        'user': user,\n",
    "        'message': message,\n",
    "        'response': response\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_interview(question):\n",
    "    response = ask_openai(question)\n",
    "    save_message_to_firestore('user1', question, response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_message_to_firestore(user, message, response):\n",
    "    doc_ref = db.collection('interviews').document()\n",
    "    doc_ref.set({\n",
    "        'user': user,\n",
    "        'message': message,\n",
    "        'response': response\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "class FirestoreCRUD:\n",
    "    def __init__(self, credential_path, collection_name):\n",
    "        cred = credentials.Certificate(credential_path)\n",
    "        # firebase_admin.initialize_app(cred)\n",
    "        self.db = firestore.client()\n",
    "        self.collection = self.db.collection(collection_name)\n",
    "\n",
    "    def create_document(self, document_id, data):\n",
    "        self.collection.document(document_id).set(data)\n",
    "\n",
    "    def read_document(self, document_id):\n",
    "        doc = self.collection.document(document_id).get()\n",
    "        if doc.exists:\n",
    "            return doc.to_dict()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def update_document(self, document_id, data):\n",
    "        self.collection.document(document_id).update(data)\n",
    "\n",
    "    def delete_document(self, document_id):\n",
    "        self.collection.document(document_id).delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_crud = FirestoreCRUD(\"/home/codered/mystuff/progs/interview-mentor-firebase-adminsdk-sguq7-aee5c6cca8.json\", \"interviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_crud.create_document(\"doc2\", {\"user\": \"user1\", \"message\": \"Hello\", \"response\": \"Hi there!\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Hello', 'user': 'user1', 'response': 'Hi there!'}\n"
     ]
    }
   ],
   "source": [
    "document = firestore_crud.read_document(\"doc1\")\n",
    "print(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_crud.update_document(\"doc1\", {\"response\": \"Hello, how can I help you?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_crud.delete_document(\"doc1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m   ]\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_client.py:93\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     91\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[67 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   error: subprocess-exited-with-error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   × python setup.py egg_info did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   │ exit code: 1\n",
      "  \u001b[31m   \u001b[0m   ╰─> [1 lines of output]\n",
      "  \u001b[31m   \u001b[0m       ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  \u001b[31m   \u001b[0m       [end of output]\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m error: metadata-generation-failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m × Encountered error while generating package metadata.\n",
      "  \u001b[31m   \u001b[0m ╰─> See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m note: This is an issue with the package mentioned above, not pip.\n",
      "  \u001b[31m   \u001b[0m hint: See above for details.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/installer.py\", line 96, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/subprocess.py\", line 413, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/home/codered/anaconda3/envs/inter_mentor/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpwnn5krkt', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-3hdurlmq/dotenv_e6aae5a738004efaa4a04320948385fb/setup.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='dotenv',\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/__init__.py\", line 106, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/__init__.py\", line 79, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     _fetch_build_eggs(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/__init__.py\", line 84, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/dist.py\", line 907, in fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     return _fetch_build_eggs(self, requires)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/installer.py\", line 38, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     resolved_dists = pkg_resources.working_set.resolve(\n",
      "  \u001b[31m   \u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 829, in resolve\n",
      "  \u001b[31m   \u001b[0m     dist = self._resolve_dist(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 865, in _resolve_dist\n",
      "  \u001b[31m   \u001b[0m     dist = best[req.key] = env.best_match(\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 1135, in best_match\n",
      "  \u001b[31m   \u001b[0m     return self.obtain(req, installer)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 1147, in obtain\n",
      "  \u001b[31m   \u001b[0m     return installer(requirement)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codered/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/setuptools/installer.py\", line 98, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     raise DistutilsError(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m distutils.errors.DistutilsError: Command '['/home/codered/anaconda3/envs/inter_mentor/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpwnn5krkt', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m load_dotenv()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "# defaults to getting the key using os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if you saved the key under a different environment variable name, you can do something like:\n",
    "# client = OpenAI(\n",
    "#   api_key=os.environ.get(\"CUSTOM_ENV_NAME\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m   ]\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_client.py:93\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     91\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conduct_interview(\u001b[39m\"\u001b[39;49m\u001b[39mhey\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconduct_interview\u001b[39m(question):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     response \u001b[39m=\u001b[39m ask_openai(question)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     save_message_to_firestore(\u001b[39m'\u001b[39m\u001b[39muser1\u001b[39m\u001b[39m'\u001b[39m, question, response)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask_openai\u001b[39m(question):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         prompt\u001b[39m=\u001b[39;49mquestion,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_args: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "conduct_interview(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m assistant \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMath Tutor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a personal math tutor. Write and run code to answer math questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_interpreter\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the equation 3x + 11 = 14 is x = 1.\n",
      "The solution to the equation 3x + 11 = 14 is x = 1.\n",
      "I need to solve the equation `3x + 11 = 14`. Can you help me?\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(messages.data)):\n",
    "    print(messages.data[i].content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "class OpenAIAssistant:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    def ask_question(self, question):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a knowledgeable interviewer.\"},\n",
    "                      {\"role\": \"user\", \"content\": question}]\n",
    "        )\n",
    "        return response.choices[0].message['content']\n",
    "\n",
    "    def score_response(self, response):\n",
    "        # Example scoring logic (can be adjusted)\n",
    "        score = len(response.split())  # Simple logic based on response length\n",
    "        return min(10, score)  # Score is capped at 10\n",
    "\n",
    "    def conduct_interview(self, question, firebase_crud):\n",
    "        response = self.ask_question(question)\n",
    "        score = self.score_response(response)\n",
    "        firebase_crud.save_message_to_firestore('interview', {'question': question, 'response': response, 'score': score})\n",
    "        return response, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m assistant \u001b[39m=\u001b[39m OpenAIAssistant()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is your view on artificial intelligence?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m response, score \u001b[39m=\u001b[39m assistant\u001b[39m.\u001b[39;49mconduct_interview(question, firestore_crud)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResponse:\u001b[39m\u001b[39m\"\u001b[39m, response)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore:\u001b[39m\u001b[39m\"\u001b[39m, score)\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconduct_interview\u001b[39m(\u001b[39mself\u001b[39m, question, firebase_crud):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mask_question(question)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_response(response)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     firebase_crud\u001b[39m.\u001b[39msave_message_to_firestore(\u001b[39m'\u001b[39m\u001b[39minterview\u001b[39m\u001b[39m'\u001b[39m, {\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m: question, \u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m: response, \u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m: score})\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask_question\u001b[39m(\u001b[39mself\u001b[39m, question):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a knowledgeable interviewer.\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                   {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: question}]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X41sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/inter_mentor/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_args: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "assistant = OpenAIAssistant()\n",
    "question = \"What is your view on artificial intelligence?\"\n",
    "response, score = assistant.conduct_interview(question, firestore_crud)\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(\"Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "class DataScienceInterviewAssistant:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.client = OpenAI()\n",
    "\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=\"Data Science Interview Assistant\",\n",
    "            instructions=\"You are a personal Data Science Interview Assistant.\",\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "        )\n",
    "\n",
    "    def conduct_interview(self, firebase_crud):\n",
    "        thread = self.client.beta.threads.create()\n",
    "\n",
    "        # Example data science interview question\n",
    "        question = \"Can you explain the concept of overfitting in machine learning?\"\n",
    "        message = self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=question\n",
    "        )\n",
    "\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=\"Please provide a detailed and accurate explanation.\"\n",
    "        )\n",
    "\n",
    "        # Wait for the response (simplified for this example)\n",
    "        # In practice, use a loop with sleep as in your example code\n",
    "        run_status = self.client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "\n",
    "        if run_status.status == 'completed':\n",
    "            messages = self.client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            for msg in messages.data:\n",
    "                if msg.role == \"assistant\":\n",
    "                    response = msg.content[0].text.value\n",
    "                    score = self.assign_score(response)  # Implement this method based on your scoring logic\n",
    "                    firebase_crud.save_message_to_firestore('interview', {'question': question, 'response': response, 'score': score})\n",
    "                    return {\"question\": question, \"response\": response, \"score\": score}\n",
    "\n",
    "    def assign_score(self, response):\n",
    "        # Implement scoring logic here\n",
    "        # For example, score can be based on the length, keywords, or other criteria\n",
    "        score = 10  # Your scoring logic\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "assistant = DataScienceInterviewAssistant()\n",
    "result = assistant.conduct_interview(firestore_crud)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Initial Interaction and Domain Inquiry\n",
    "\n",
    "Begin the interaction with a friendly greeting.\n",
    "Ask the user about their target domain for the mock interview. Example: \"Hello! I'm your Mock Interview Mentor. What domain are you preparing for? Tech, Finance, Healthcare?\"\n",
    "CV Submission Request\n",
    "\n",
    "Suggest that the user provide their CV to enhance the interview process. Example: \"If you'd like, you can share your CV with me. This will help me tailor the questions specifically to your background and experience.\"\n",
    "Tailoring Questions Based on Domain and CV\n",
    "\n",
    "Analyze the user's domain and the details provided in the CV.\n",
    "Prepare and ask questions relevant to the domain and the information in the CV. This includes role-specific questions, experience-based scenarios, and competency inquiries.\n",
    "One-Question-at-a-Time Approach\n",
    "\n",
    "Pose one question at a time, allowing the user to respond without feeling rushed.\n",
    "Ensure that the questions are clear and understandable.\n",
    "Providing Ratings and Feedback\n",
    "\n",
    "After each response from the user, offer a rating and constructive feedback. This could be based on the content, clarity, relevance, and confidence in the response.\n",
    "Feedback should be specific, actionable, and supportive. Example: \"Your answer was well-structured, but you might want to include more specific examples related to project management.\"\n",
    "Ensuring a Thorough Interview Experience\n",
    "\n",
    "The interview should cover various aspects, including technical skills, soft skills, and situational responses.\n",
    "Maintain a respectful and encouraging tone throughout the interview.\n",
    "Conclusion and Overall Feedback\n",
    "\n",
    "At the end of the interview, provide a summary of the user’s performance, highlighting strengths and areas for improvement.\n",
    "Thank the user for participating and encourage them for their upcoming real interviews.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class DataScienceInterviewAssistant:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.client = openai.OpenAI()\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=\"Data Science Interview Assistant\",\n",
    "            instructions=instruction,\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "        )\n",
    "\n",
    "    def conduct_interview(self, question):\n",
    "\n",
    "        tools_list = [\n",
    "    # ... your existing tools ...\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"score_response\",\n",
    "                    \"description\": \"Assign a score from 0 to 10 based on the quality of the interview response\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"response\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The interview response to be scored\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"response\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        thread = self.client.beta.threads.create()\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=question\n",
    "        )\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            time.sleep(5)\n",
    "            run_status = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "            if run_status.status == 'completed':\n",
    "                messages = self.client.beta.threads.messages.list(\n",
    "                    thread_id=thread.id\n",
    "                )\n",
    "                interview_responses = []\n",
    "                for msg in messages.data:\n",
    "                    role = msg.role\n",
    "                    content = msg.content[0].text.value\n",
    "                    interview_responses.append({\"role\": role, \"content\": content})\n",
    "                break\n",
    "            elif run_status.status == 'requires_action':\n",
    "                # Handle any required actions if needed\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Assign a random score for simplicity\n",
    "        score = random.randint(1, 10)\n",
    "        return interview_responses, score\n",
    "    \n",
    "    def list_threads(self):\n",
    "        # List all threads\n",
    "        threads = self.client.beta.threads.list()\n",
    "        return threads.data\n",
    "\n",
    "    def get_thread_messages(self, thread_id):\n",
    "        # Retrieve messages from a specific thread\n",
    "        messages = self.client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        return messages.data\n",
    "\n",
    "    def print_thread_conversation(self, thread_id):\n",
    "        # Print the conversation of a specific thread\n",
    "        messages = self.get_thread_messages(thread_id)\n",
    "        for msg in messages:\n",
    "            print(f\"{msg.role.capitalize()}: {msg.content[0].text.value}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataScienceInterviewAssistant.__init__() missing 1 required positional argument: 'instruction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 31\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# # Assuming FirestoreCRUD is already set up\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# from your_firebase_crud_module import FirestoreCRUD\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# firebase_crud = FirestoreCRUD(...)  # Initialize with appropriate parameters\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m assistant \u001b[39m=\u001b[39m DataScienceInterviewAssistant()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHey\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m responses, score \u001b[39m=\u001b[39m assistant\u001b[39m.\u001b[39mconduct_interview(question)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataScienceInterviewAssistant.__init__() missing 1 required positional argument: 'instruction'"
     ]
    }
   ],
   "source": [
    "# # Assuming FirestoreCRUD is already set up\n",
    "# from your_firebase_crud_module import FirestoreCRUD\n",
    "\n",
    "# firebase_crud = FirestoreCRUD(...)  # Initialize with appropriate parameters\n",
    "\n",
    "assistant = DataScienceInterviewAssistant()\n",
    "question = \"Hey\"\n",
    "responses, score = assistant.conduct_interview(question)\n",
    "\n",
    "print(\"Interview Responses:\", responses)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Save the result to Firebase\n",
    "# firestore_crud.create_document('interview', {'question': question, 'score': score})\n",
    "firestore_crud.create_document(\"user1\", {\"question\": question, 'score': score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Threads' object has no attribute 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m threads \u001b[39m=\u001b[39m assistant\u001b[39m.\u001b[39;49mlist_threads()\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 32\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X53sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist_threads\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X53sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# List all threads\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X53sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     threads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mbeta\u001b[39m.\u001b[39;49mthreads\u001b[39m.\u001b[39;49mlist()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X53sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m threads\u001b[39m.\u001b[39mdata\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Threads' object has no attribute 'list'"
     ]
    }
   ],
   "source": [
    "threads = assistant.list_threads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class DataScienceInterviewAssistant:\n",
    "    def __init__(self, instruction):\n",
    "            self.client = openai.OpenAI()\n",
    "            self.assistant = self.client.beta.assistants.create(\n",
    "                name=\"Data Science Interview Assistant\",\n",
    "                instructions=instruction,\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "            )\n",
    "            self.thread = self.client.beta.threads.create()\n",
    "            print(f\"Thread created with ID: {self.thread.id}\")\n",
    "\n",
    "    def conduct_interview(self, question):\n",
    "        thread = self.thread\n",
    "        print(f\"Thread created with ID: {thread.id}\")  # Print the thread ID\n",
    "        \n",
    "        # init user \n",
    "        # self.client.beta.threads.messages.create(\n",
    "        #     thread_id=thread.id,\n",
    "        #     role=\"user\",\n",
    "        #     content=\"Hey\"\n",
    "        # )\n",
    "\n",
    "        # user\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=question,\n",
    "        )\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            time.sleep(5)\n",
    "            run_status = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "            if run_status.status == 'completed':\n",
    "                messages = self.client.beta.threads.messages.list(\n",
    "                    thread_id=thread.id\n",
    "                )\n",
    "                interview_responses = []\n",
    "                for msg in messages.data:\n",
    "                    role = msg.role\n",
    "                    content = msg.content[0].text.value\n",
    "                    interview_responses.append({\"role\": role, \"content\": content})\n",
    "                break\n",
    "            elif run_status.status == 'requires_action':\n",
    "                # Handle any required actions if needed\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Assign a random score for simplicity\n",
    "        score = random.randint(1, 10)\n",
    "        return interview_responses, score\n",
    "\n",
    "    def get_thread_messages(self, thread_id):\n",
    "        # Retrieve messages from a specific thread\n",
    "        messages = self.client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        return messages.data\n",
    "\n",
    "    def print_thread_conversation(self, thread_id):\n",
    "        # Print the conversation of a specific thread\n",
    "        messages = self.get_thread_messages(thread_id)\n",
    "        for msg in messages:\n",
    "            print(f\"{msg.role.capitalize()}: {msg.content[0].text.value}\")\n",
    "\n",
    "    def get_thread_id(self):\n",
    "        return self.thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created with ID: thread_B1f9t5w1qLKTJAFDSBqYKOoT\n"
     ]
    }
   ],
   "source": [
    "assistant = DataScienceInterviewAssistant(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created with ID: thread_B1f9t5w1qLKTJAFDSBqYKOoT\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Messages.create() got an unexpected keyword argument 'instruction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 35\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# # Assuming FirestoreCRUD is already set up\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# from your_firebase_crud_module import FirestoreCRUD\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# firebase_crud = FirestoreCRUD(...)  # Initialize with appropriate parameters\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhey\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m responses, score \u001b[39m=\u001b[39m assistant\u001b[39m.\u001b[39;49mconduct_interview(question)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInterview Responses:\u001b[39m\u001b[39m\"\u001b[39m, responses)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore:\u001b[39m\u001b[39m\"\u001b[39m, score)\n",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 35\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThread created with ID: \u001b[39m\u001b[39m{\u001b[39;00mthread\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# Print the thread ID\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# init user \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# self.client.beta.threads.messages.create(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     thread_id=thread.id,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# user\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mbeta\u001b[39m.\u001b[39;49mthreads\u001b[39m.\u001b[39;49mmessages\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     thread_id\u001b[39m=\u001b[39;49mthread\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     role\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     content\u001b[39m=\u001b[39;49mquestion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     instruction\u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mAfter answering the question, please also provide a score from 0 to 10 based on the quality of the response.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mruns\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     assistant_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39massistant\u001b[39m.\u001b[39mid,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X55sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Messages.create() got an unexpected keyword argument 'instruction'"
     ]
    }
   ],
   "source": [
    "# # Assuming FirestoreCRUD is already set up\n",
    "# from your_firebase_crud_module import FirestoreCRUD\n",
    "\n",
    "# firebase_crud = FirestoreCRUD(...)  # Initialize with appropriate parameters\n",
    "\n",
    "\n",
    "question = \"hey\"\n",
    "responses, score = assistant.conduct_interview(question)\n",
    "\n",
    "print(\"Interview Responses:\", responses)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Save the result to Firebase\n",
    "# firestore_crud.create_document('interview', {'question': question, 'score': score})\n",
    "thread_id = assistant.get_thread_id()\n",
    "firestore_crud.create_document(str(thread_id), {\"question\": question, 'score': score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! I'm your Mock Interview Mentor. What domain are you preparing for? Tech, Finance, Healthcare?\n",
      "User: hey\n"
     ]
    }
   ],
   "source": [
    "assistant.print_thread_conversation(assistant.get_thread_id().id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  }, {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getNickname\",\n",
    "      \"description\": \"Get the nickname of a city\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    } \n",
    "  }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'call_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 38\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m run \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mruns\u001b[39m.\u001b[39msubmit_tool_outputs(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mid,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   tool_outputs\u001b[39m=\u001b[39m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       {\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtool_call_id\u001b[39m\u001b[39m\"\u001b[39m: call_ids[\u001b[39m0\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m22C\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       },\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtool_call_id\u001b[39m\u001b[39m\"\u001b[39m: call_ids[\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mLA\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m       },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'call_ids' is not defined"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id,\n",
    "  tool_outputs=[\n",
    "      {\n",
    "        \"tool_call_id\": call_ids[0],\n",
    "        \"output\": \"22C\",\n",
    "      },\n",
    "      {\n",
    "        \"tool_call_id\": call_ids[1],\n",
    "        \"output\": \"LA\",\n",
    "      },\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Retrieve the latest closing price of a stock using its ticker symbol\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ticker symbol of the stock\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"symbol\"]\n",
    "        }\n",
    "    }\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"u have asked a question to user for under fitting and he havs given the response, no give him feedback and a score from 1 to 10.\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=tools_list\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"overfitting when the model peforms well in training and bad in testing and under fitting is when the model peforsa bad in botht case\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  # instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_C0sbSVD5p1QbkcfBUk6h5uQf', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='overfitting when the model peforms well in training and bad in testing and under fitting is when the model peforsa bad in botht case'), type='text')], created_at=1702302785, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_KvIsiEDKXnHmOT8tVOCaYJcU')], object='list', first_id='msg_C0sbSVD5p1QbkcfBUk6h5uQf', last_id='msg_C0sbSVD5p1QbkcfBUk6h5uQf', has_more=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb Cell 42\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#Y103sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_stock_price\u001b[39m(symbol: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/codered/mystuff/progs/python/interview_mentor/test_call.ipynb#Y103sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     stock \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39mTicker(symbol)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str) -> float:\n",
    "    stock = yf.Ticker(symbol)\n",
    "    price = stock.history(period=\"1d\")['Close'].iloc[-1]\n",
    "    return price\n",
    "\n",
    "\n",
    "tools_list = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Retrieve the latest closing price of a stock using its ticker symbol\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ticker symbol of the stock\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"symbol\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "\n",
    "# Initialize the client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Step 1: Create an Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Data Analyst Assistant\",\n",
    "    instructions=\"You are a personal Data Analyst Assistant\",\n",
    "    tools=tools_list,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "# Step 2: Create a Thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Step 3: Add a Message to a Thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you please provide me stock price of Apple?\"\n",
    ")\n",
    "\n",
    "# Step 4: Run the Assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Mervin Praison.\"\n",
    ")\n",
    "\n",
    "print(run.model_dump_json(indent=4))\n",
    "\n",
    "while True:\n",
    "    # Wait for 5 seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.model_dump_json(indent=4))\n",
    "\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            content = msg.content[0].text.value\n",
    "            print(f\"{role.capitalize()}: {content}\")\n",
    "\n",
    "        break\n",
    "    elif run_status.status == 'requires_action':\n",
    "        print(\"Function Calling\")\n",
    "        required_actions = run_status.required_action.submit_tool_outputs.model_dump()\n",
    "        print(required_actions)\n",
    "        tool_outputs = []\n",
    "        import json\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            func_name = action['function']['name']\n",
    "            arguments = json.loads(action['function']['arguments'])\n",
    "            \n",
    "            if func_name == \"get_stock_price\":\n",
    "                output = get_stock_price(symbol=arguments['symbol'])\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": action['id'],\n",
    "                    \"output\": output\n",
    "                })\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown function: {func_name}\")\n",
    "            \n",
    "        print(\"Submitting outputs back to the Assistant...\")\n",
    "        client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n",
    "    else:\n",
    "        print(\"Waiting for the Assistant to process...\")\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
